---
title: "Hotel: Classifying with Children or not"
date: "March 5, 2025"
format: 
  html:
    self-contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

> 1. Build the PENALIZED LOGISTIC REGRESSION model the hotel data. 

The recipe is the pre-processing steps for preparing the data. 

The recipe set up the function to fit the model using training data. For this study, the recipe of the first model create new predictors for the date and holiday separately, then remove the original variables. It convert the factors variable into dummy variable so that they can fit into the model. For the penalized model, it required normalize the variables so that in the recipe which removes the variables only has 1 unique value then normalized the other variables. 

The recipe of the second model did not required dummy variables and normalization.

The workflow creating a working place for the data and function in the recipe to fit the model.

To improve the model, the parameter penalty is tuning. 

The tune_grid of the first model using the workflow to test a group of possible penalty values and pick the one which gives the best roc-auc. Using that penalty value for the model will gives the best model. In this study, smaller penalty gives better model performance for the first model. 

The tune_grid of the second model using to tuning 2 parameters which are number of trees and minimum size. The tune_grid pick the best combination of mtry and min_n which gives the best roc_auc.

> 2. Build the TREE-BASED ENSEMBLE model the hotel data.

> 3. Compare the ROC Curve for the two models.

From comparing the ROC Curve, the random forest model which is the second model performs better for classifying a a hotel booking as with children or no children. The sensitivity tells how well a test identifies true positive cases. The 1-specificity tells probability a test identifies true negative cases as positive cases. Therefore, the curve more close to the top left corner performs better. It indicates the model has ability to test more accurate on positive cases.

# Introduction

```{r}
library(tidymodels)  

# Helper packages
library(readr)       # for importing data
library(vip)         # for variable importance plots
```

# The Hotel Bookings Data

```{r}
hotels <- 
  read_csv("https://tidymodels.org/start/case-study/hotels.csv") %>%
  mutate(across(where(is.character), as.factor))

dim(hotels)

glimpse(hotels)
```

```{r}
hotels %>% 
  count(children) %>% 
  mutate(prop = n/sum(n))
```

# Data Splitting & Resampling

```{r}
set.seed(123)
splits <- initial_split(hotels, strata = children)

hotel_other <- training(splits)
hotel_test  <- testing(splits)

# training set proportions by children
hotel_other %>% 
  count(children) %>% 
  mutate(prop = n/sum(n))

# test set proportions by children
hotel_test  %>% 
  count(children) %>% 
  mutate(prop = n/sum(n))
```

```{r}
set.seed(234)
val_set <- validation_split(hotel_other, 
                            strata = children, 
                            prop = 0.80)

val_set
```

# A first model: penalized logistic regression

## Build the model

```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")
```

## Create the recipe

```{r}
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(children ~ ., data = hotel_other) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date, holidays = holidays) %>% 
  step_rm(arrival_date) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
```

## Create the workflow

```{r}
lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

## Create the grid for tuning

```{r}
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))

lr_reg_grid %>% top_n(-5) # lowest penalty values

lr_reg_grid %>% top_n(5)  # highest penalty values
```

## Train and tune the model

```{r}
lr_res <- 
  lr_workflow %>% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

```{r}
lr_plot <- 
  lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

lr_plot 
```

```{r}
top_models <-
  lr_res %>% 
  show_best(metric = "roc_auc", n = 15) %>% 
  arrange(penalty) 
top_models
```

```{r}
lr_best <- 
  lr_res %>% 
  collect_metrics() %>% 
  arrange(penalty) %>% 
  slice(12)
lr_best
```

```{r}
lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```

# A second model: tree-based ensemble

## Build the model and improve training time

```{r}
cores <- parallel::detectCores() - 1
cores
```

```{r}
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger", num.threads = cores) %>% 
  set_mode("classification")
```

## Create the recipe and workflow

```{r}
rf_recipe <- 
  recipe(children ~ ., data = hotel_other) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date) %>% 
  step_rm(arrival_date)
```

```{r}
rf_workflow <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(rf_recipe)
```

## Train and tune the model

```{r}
rf_mod

extract_parameter_set_dials(rf_mod)
```

```{r}
set.seed(345)
rf_res <- 
  rf_workflow %>% 
  tune_grid(val_set,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
#> i Creating pre-processing data to finalize unknown parameter: mtry
```

```{r}
rf_res %>% 
  show_best(metric = "roc_auc")
```

```{r}
autoplot(rf_res)
```

```{r}
rf_best <- 
  rf_res %>% 
  select_best(metric = "roc_auc")
rf_best
```

```{r}
rf_res %>% 
  collect_predictions()
```

```{r}
rf_auc <- 
  rf_res %>% 
  collect_predictions(parameters = rf_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Random Forest")
```

```{r}
bind_rows(rf_auc, lr_auc) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)
```

# The last fit

```{r}
# the last model
last_rf_mod <- 
  rand_forest(mtry = 8, min_n = 7, trees = 1000) %>% 
  set_engine("ranger", num.threads = cores, importance = "impurity") %>% 
  set_mode("classification")

# the last workflow
last_rf_workflow <- 
  rf_workflow %>% 
  update_model(last_rf_mod)

# the last fit
set.seed(345)
last_rf_fit <- 
  last_rf_workflow %>% 
  last_fit(splits)

last_rf_fit
```

```{r}
last_rf_fit %>% 
  collect_metrics()
```

```{r}
last_rf_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```

```{r}
last_rf_fit %>% 
  collect_predictions() %>% 
  roc_curve(children, .pred_children) %>% 
  autoplot()
```

